---
title: "Ma-Cantine : Bilan statistique 2023"
author:
  - "Quentin Loridant"
date: "2023-05-24"
format:
  html:
    embed-resources: true
    code-fold: true
    theme:
      - readable
    toc: true
    toc-depth: 2
execute:
  warning: false
  cache: true
---

# Introduction

## Contexte

Le bilan statistique annuel de l’application des objectifs d’approvisionnement fixés à la restauration collective donne lieu à un rapport du gouvernement qui est remis au parlement chaque année.
Celui-ci contient une analyse des données de la campagne de télédéclaration. Le premier bilan est disponible pour la [campagne 2022](https://1648047458-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-MSCF7Mdc8yfeIjMxMZr%2Fuploads%2F6RxGNr0aJ4BPSzFsDQGs%2FBilan%20statistique%20EGAlim_achats2021.pdf?alt=media&token=).

Dans ce document nous créeons et documentons les statistiques nécessaires pour la campagne 2023. Cette campagne a eu lieu sur le premier semestre 2023 et porte sur les données de l'année 2022.

## Changements par rapport à la campagne 2022

En 2021, l'application ne permettait pas de spécifier le mode de télédéclaration (cuisine centrale ou satellite). Pour la campagne 2023, il est possible que la télédéclaration soit rensignée soit par :

* une cuisine préparant ses propres repas
* une cuisine centrale (dans ce cas elle peut renseigner les données pour ces satellites)
* une cuisine satellite directement


```{python import}
# | echo: false
import pandas as pd
import os
import datetime
import requests
import json
from dotenv import load_dotenv
from ydata_profiling import ProfileReport
import psycopg2
import plotly.express as px
import matplotlib.pyplot as plt
from matplotlib import dates as mdates
import locale

```



```{python Import des données des campagnes}
# | echo: false
campagnes = {
    "2021": {"start_date": "2022-07-16", "end_date": "2022-12-05", "card": "795"},
    "2022": {"start_date": "2023-02-13", "end_date": "2023-06-30", "card": "802"},
}
```

<!-- Afin de récupérer les données, il vous faut un TOKEN metabase :
`curl -X POST -H "Content-Type: application/json" -d '{"username": <USERNAME>, "password": <PASSWORD>}' https://ma-cantine-metabase.cleverapps.io/api/session` -->


```{python Import des données TD}
# | echo: false
url = f"https://ma-cantine-metabase.cleverapps.io/api/card/802/query/json"
load_dotenv()
header = {
    "Content-Type": "application/json",
    "X-Metabase-Session": os.environ.get("METABASE_TOKEN"),
}
res = requests.post(
    url,
    headers=header,
)
td_raw = pd.DataFrame(res.json())
del td_raw["year"]
td_raw["declared_data"] = td_raw["declared_data"].apply(json.loads)
td_json = pd.json_normalize(td_raw["declared_data"])
td_raw = pd.concat([td_raw.drop("declared_data", axis=1), td_json], axis=1)
```

Les données sont extraites de la base de données de ma-cantine. Plusieurs filtres sont appliqués :

1. date : les télédéclarations doivent être comprises dans les dates de campagne: `creation_date BETWEEN XX mars au 30 juin 2023`
2. statut : la télédéclaration doit avoir été validée par son éditeur. `status="SUBMITTED"`
3. année 2022 : `year==2022`
4. canteen ID qui sont renseignés (champs non nuls) : `canteen_id.notnull()`

Vous pouvez retrouver le code utilisé pour ces filtres ci dessous :

```{python Ajout des données cantines pour les td de la campagne 2022}
def add_canteen_info(df):
    url = f"https://ma-cantine-metabase.cleverapps.io/api/card/820/query/json"
    res = requests.post(
        url,
        headers={
            "Content-Type": "application/json",
            "X-Metabase-Session": os.environ.get("METABASE_TOKEN"),
        },
    )
    td_canteen = pd.DataFrame(res.json())
    col_to_rename = {}
    for col in ["production_type", "management_type", "yearly_meal_count", "daily_meal_count", "sectors"]:
        del df[f"canteen.{col}"]
        col_to_rename[f"{col}"] = f"canteen.{col}"
    td_canteen = td_canteen.rename(columns=col_to_rename)

    df = df.merge(right=td_canteen, left_on="canteen_id", right_on="id")
    return df


```

```{python Nettoyage des données}
td = td_raw.copy()
td = td[td.status == "SUBMITTED"]
td = td[td.canteen_id.notnull()]
tds = {}
for year in campagnes.keys():
    tds[year] = td.copy()
    tds[year] = tds[year][tds[year].year == int(year)]
    tds[year]["creation_date"] = tds[year]["creation_date"].apply(lambda x: x.split("T")[0])
    tds[year] = tds[year][
        (tds[year]["creation_date"] >= campagnes[year]["start_date"])
        & (tds[year]["creation_date"] <= campagnes[year]["end_date"])
    ]

tds["2021"] = add_canteen_info(tds["2021"])

for year in campagnes.keys():
    tds[year].to_csv(f"export_dataset_stats_campagne_{year}.csv", sep=";", index=False)

```



# Comparaison de la dynamique de télédéclarations lors des deux dernières campagnes. 
```{python}

tds_ts = {}
for year in campagnes.keys():
    tds_ts[year] = tds[year].copy()
    tds_ts[year]["creation_date"] = pd.to_datetime(tds_ts[year]["creation_date"])  # .dt.strftime('%V')
    tds_ts[year] = tds_ts[year].groupby("creation_date").count()
    tds_ts[year] = tds_ts[year].rename(columns={"canteen_id": "cmpt_td_2022"})

locale.setlocale(locale.LC_TIME, "fr_FR.utf8")

axe = 0
fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 6))
for year in tds_ts.keys():
    axes[axe].plot(tds_ts[year].index, tds_ts[year]["cmpt_td_2022"])
    # Set the x-axis tick locator and formatter
    locator = mdates.MonthLocator()
    formatter = mdates.DateFormatter("%b")  # %b for abbreviated month name

    axes[axe].xaxis.set_major_locator(locator)
    axes[axe].xaxis.set_major_formatter(formatter)
    axes[axe].set_ylabel("Nombre de télédéclaration")
    axes[axe].set_title(f"Historique des télédeclarations de la campagne {int(year) -1} sur les données {year}")
    axes[axe].legend()
    axes[axe].grid(True)
    axe += 1

plt.tight_layout()
plt.show()
```

On observe plusieurs éléments : 

* les durées sont similaires 
* décalage de 6 mois entre les deux campagnes 
* dans les deux cas, nous observons le phénomène de "la dernière minute" : forte augmentation du nombre télédéclaration avant la fin des échéances 
* la deuxième campagne est plus régulière, avec l'observation d'une semaine type 


```{python Vérification des données}
# | echo: false
for year in tds.keys():
    assert (
        tds[year].groupby("canteen_id").size().sort_values(ascending=False).head(1).iloc[0] == 1
    ), "Il y a des doublons de canteen_id"
    assert tds[year]["canteen_id"].isna().sum() == 0, "Il y a des cantines sans identifiant"
    assert len(tds[year]["canteen_id"]) == len(
        tds[year]["canteen_id"].unique()
    ), "Il y a des doublons dans les cantines"
```

# Traitement des valeurs manquantes
Si nous souhaitons coller au maximum au traitement effectué pour la campagne 2021, nous devons remplaçer les valeurs manquantes par la valeur 0.
```{python Basic}

# for year in ['2021', '2022']:
#     tds[year] = tds[year].fillna(0)
```

# Qualité des données

Avant d'étudier les chiffres clés de la télédéclaration, nous vous présentons des informations sur la qualité des données. Ces informations sont importantes pour saisir au mieux la portée des indicateurs.


```{python Vérification du taux de présence de la donnée repas par an}
# | echo: false
# | output: asis

print("::: {.spoiler} \n")
pourcentage_in_file = {}
for year in campagnes.keys():
    pourcentage_in_file[year] = {}
    for col in tds[year].columns:
        pourcentage_in_file[year][col] = f"{100 * (1 - tds[year][col].isna().sum() / len(tds[year])):.2f} %"

pourcentage_in_file_to_display = pd.DataFrame(pourcentage_in_file)
# print(pourcentage_in_file_to_display.to_markdown())
print(":::")
```

# Chiffres clés

Dans les télédéclarations pour la campagne 2022 (données 2021), il n'y a pas d'indication du nombre de satellites, du managment_type et du production_type.

Ces informations suivantes proviennent donc des informations renseignées pour les cantines. Les données ont peut-être légérement été modifié depuis la télédéclaration.

```{python Nombre de sites de restauration concernés par la télédéclaration}
# | echo: false
# | output: asis

indicateurs = {}
for year in campagnes.keys():
    indicateurs[year] = {}
    indicateurs[year]["Nombre de Télédéclarations"] = len(tds[year])
    indicateurs[year]["Nombre de sites de restauration concernés par la télédéclaration"] = (
        len(tds[year]) + tds[year]["satellite_canteens_count"].sum()
    )
    cuisines_sur_place = tds[year][tds[year]["canteen.production_type"].isin(["site", "site_cooked_elsewhere"])]
    indicateurs[year]["Nombre de cantines sur place (sites et satellites)"] = len(cuisines_sur_place)

    cuisines_centrales = tds[year][tds[year]["canteen.production_type"].isin(["central_serving", "central"])]

    indicateurs[year]["Nombre de repas moyens par jour pour les cantines sur place"] = int(
        cuisines_sur_place["canteen.daily_meal_count"].mean()
    )
    indicateurs[year]["Nombre de repas moyens par jour pour les cantines centrales"] = int(
        cuisines_centrales["canteen.daily_meal_count"].mean()
    )
    indicateurs[year]["Nombre de repas totaux pour l'année"] = int(tds[year]["canteen.yearly_meal_count"].sum())

    indicateurs[year][
        "Répartition du nombre de cantines en gestion directe"
    ] = f"{100 * len(tds[year][tds[year]['canteen.management_type'] == 'direct']) / len(tds[year]):.2f} %"
    indicateurs[year][
        "Répartition du nombre de cantines en gestion concédée"
    ] = f"{100 * len(tds[year][tds[year]['canteen.management_type'] == 'conceded']) / len(tds[year]):.2f} %"
    indicateurs[year][
        "Répartition du nombre de cantines en gestion non renseignée"
    ] = f"{100 * len(tds[year][~tds[year]['canteen.management_type'].isin(['direct', 'conceded'])]) / len(tds[year]):.2f} %"

    indicateurs[year][
        "Montants d'achat alimentaires déclarés"
    ] = f"{int(tds[year]['teledeclaration.value_total_ht'].sum())} €"

    indicateurs[year][
        "Taux global des achats en bio"
    ] = f"{100 * tds[year]['teledeclaration.value_bio_ht'].sum() / tds[year]['teledeclaration.value_total_ht'].sum():.2f} %"

    indicateurs[year][
        "Taux global des achats EGALIM (bio inclus)"
    ] = f"{100 * (tds[year]['teledeclaration.value_egalim_others_ht'].sum() + tds[year]['teledeclaration.value_externality_performance_ht'].sum() + tds[year]['teledeclaration.value_bio_ht'].sum()  + tds[year]['teledeclaration.value_sustainable_ht'].sum()) / tds[year]['teledeclaration.value_total_ht'].sum():.2f} %"

    indicateurs[year]["Nombre de TD ayant déclaré 0€ d'achats en Bio"] = len(
        tds[year][tds[year]["teledeclaration.value_bio_ht"] == 0]
    )

indicateurs_to_display = pd.DataFrame(indicateurs)
print(indicateurs_to_display.to_markdown())
```



# Focus par secteurs
Répartition des télédéclaration en fonction du secteur principal.

```{python}
# | echo: false
# | output: asis


def traitement_secteurs(df, year):
    df["canteen.sectors"] = tds[year]["canteen.sectors"].fillna("[]")
    if year != "2021":  # Transform the dict into a list of category
        df["canteen.sectors_"] = df["canteen.sectors"].apply(lambda x: ["sector." + item["category"] for item in x])
        # print(df["canteen.sectors_"])
    else:
        df["canteen.sectors_"] = df["canteen.sectors"].apply(lambda x: x.split(","))
        # print(df["canteen.sectors_"])

    # Explode the lists into separate rows
    df_exploded = df.explode("canteen.sectors_")

    # Use get_dummies to create dummy columns for each category
    categories_dummies = pd.get_dummies(df_exploded["canteen.sectors_"])

    # Group by the index (items) and sum the dummy columns

    categories_dummies_grouped = categories_dummies.groupby(by=categories_dummies.index).sum()
    # Concatenate the dummy columns with the original DataFrame
    df_normalized = pd.concat([df, categories_dummies_grouped], axis=1)

    # Drop the 'categories' column since we have the dummies
    df_normalized = df_normalized.drop(columns=["canteen.sectors_"])

    return df_normalized


for year in campagnes.keys():
    tds[year] = traitement_secteurs(tds[year], year)
    categories = list(filter(lambda k: "sector." in k, tds[year].columns))

sectors = pd.DataFrame({"2021": tds["2021"][categories].sum(), "2022": tds["2022"][categories].sum()})
print(sectors.to_markdown())

```

```{python}
for year in campagnes.keys():
    for category in categories:
        print('\n#####\n' + category + '\n')
        tds[year] = tds[year].loc[:, ~tds[year].columns.duplicated()]
        print(tds[year][tds[year][category] > 0][['canteen_id', 'teledeclaration.value_bio_ht']].describe())
```
## Secteur Administration


## Etudes des populations de déclarants

```{python}
# First we want a dataframe in which each line represent a canteen, whatever its production type (central, satellite...). In order to do this, we need to dig in the line of the central kitchen
# for year in campagnes.keys():

```


# Traitement des champs manquants, stratégie 2022

## Stratégie 2022

Si les 4 champs sont vides => on ne force pas à 0 (108 cantines concernés)

* Pour le calcul du bio -> mettre les valeurs à 0
* Pour le calcul du EGAlim -> mettre les valeurs à 0

* Pour les TD complètes de la campagne , on ne retrouvait pas les bonnes valeurs : total bio et somme des achats bio
22 TD complètes. Le total des achats bio est rempli automatiquement. Le calcul ne correspondait pas à la somme de tous les produits bio. Corrigé ?


## Stratégie 2023

* Normalement, champ "je ne sais pas"
* Import par fichiers, il y a peut-être des champs vides, ou des valeurs à 0
* Valeurs vides => on ne prend pas en compte la colonne pour les calculs


# Changelog pour la campagne 2022

* Supprimer les cuisine centrales du calcul du nombre de site de restauration concerné
* Se rebaser sur les données cantine fournies dans la télédéclaration
* Nombre de repas moyen : on se rebase sur les données cantine fournies dans la télédéclaration (et non pas une approximation détaillée par secteur)
* (eventuellement) Changer la stratégie pour les champs vides

# Analyses à mener

* Pertinence des garde fous (bloquant et non bloquant) (cf Matomo)
* Nombre de déclarants ont rempli des valeurs d'achat bio (O € compris)
* Même télédeclarant que l'année dernière ? est-ce que leur pourcentage de bio est cohérent avec l'année dernière ?
* Est-ce que les nouveaux télédeclarants ont un pourcentage de bio qui contribue à la baisse ou à la hausse du pourcentage de bio global ?
* Répartition individuelle des des répartition du bio . Moyenne du pourcentage
* Stats par familles d'achat
* Mesurer l'effort de TD entre 3 semaine avant la date limite et la date limite
