---
title: "Bilan statistique de la campagne ma-cantine portant sur l'année 2022 (travail en cours)"
author:
  - "Quentin Loridant"
date: "2023-09-07"
format:
  html:
    embed-resources: true
    code-fold: true
    theme:
      - readable
    toc: true
    toc-depth: 2
execute:
  warning: false
  cache: true
---

# Introduction

## Contexte

Le bilan statistique annuel de l’application des objectifs d’approvisionnement fixés à la restauration collective donne lieu à un rapport du gouvernement qui est remis au parlement chaque année.
Celui-ci contient une analyse des données de la campagne de télédéclaration. Le premier bilan est disponible pour la [campagne portant sur les données 2021](https://1648047458-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-MSCF7Mdc8yfeIjMxMZr%2Fuploads%2F6RxGNr0aJ4BPSzFsDQGs%2FBilan%20statistique%20EGAlim_achats2021.pdf?alt=media&token=).

Dans ce document nous créons et documentons les statistiques nécessaires pour la campagne ayant eu lieu sur le premier semestre 2023 et portant sur les données de l'année 2022.


```{python import}
# | echo: false
import pandas as pd
import numpy as np
import ast
import os
import datetime
import requests
import json
from dotenv import load_dotenv
from ydata_profiling import ProfileReport
import psycopg2
import plotly.express as px
import matplotlib.pyplot as plt
from matplotlib import dates as mdates
import locale

```



```{python Import des données des campagnes}
# | echo: false

# cache=True

campagnes = {
    "2021": {"start_date": "2022-07-16", "end_date": "2022-12-05", "card": "795"},
    "2022": {"start_date": "2023-02-13", "end_date": "2023-06-30", "card": "802"},
}

SECTORS = {
    "ESAT/établissements spécialisés": "social",
    "Secondaire lycée (hors agricole)": "education",
    "Restaurants inter-entreprises": "enterprise",
    "Restaurants d’entreprises": "enterprise",
    "Secondaire Lycée agricole": "education",
    "Restaurants inter-administratifs d’Etat (RIA)": "administration",
    "Cliniques": "health",
    "Autres établissements sociaux et médicaux sociaux": "social",
    "Restaurants des prisons": "administration",
    "Autres structures d’enseignement": "education",
    "Secondaire collège": "education",
    "Autres etablissements du secteur public": "administration",
    "Autres établissements de loisirs": "leisure",
    "Centre de vacances/sportif": "leisure",
    "Autres établissements de soins": "health",
    "Autres etablissements non listés": "autres",
    "Crèche": "social",
    "Ecole primaire (maternelle et élémentaire)": "education",
    "Restaurants des armées/police/gendarmerie": "administration",
    "Restaurants administratifs d’Etat (RA)": "administration",
    "EHPAD/ maisons de retraite / foyers de personnes âgées": "social",
    "Restaurants administratifs des collectivités territoriales": "administration",
    "IME/ITEP": "social",
    "Hôpitaux": "health",
    "Supérieur et Universitaire": "education",
}
```

<!-- Afin de récupérer les données, il vous faut un TOKEN metabase :
`curl -X POST -H "Content-Type: application/json" -d '{"username": <USERNAME>, "password": <PASSWORD>}' https://ma-cantine-metabase.cleverapps.io/api/session` -->


```{python Import des données TD}
# | echo: false

def load_td():
    url = f"https://ma-cantine-metabase.cleverapps.io/api/card/802/query/json"
    load_dotenv()

    if not os.environ.get("METABASE_TOKEN"):
        raise Exception("Pas de token Metabase trouvé")

    header = {
        "Content-Type": "application/json",
        "X-Metabase-Session": os.environ.get("METABASE_TOKEN"),
    }
    res = requests.post(
        url,
        headers=header,
    )

    if res.status_code != 200:
        raise Exception(f"Request failed : {res.status_code}")

    td_raw = pd.DataFrame(res.json())
    del td_raw["year"]
    td_raw["declared_data"] = td_raw["declared_data"].apply(json.loads)
    td_json = pd.json_normalize(td_raw["declared_data"])
    td_raw = pd.concat([td_raw.drop("declared_data", axis=1), td_json], axis=1)
    return td_raw
```

Les données sont extraites de la base de données de ma-cantine. Plusieurs filtres sont appliqués :

1. date : les télédéclarations doivent être comprises dans les dates de campagne: `creation_date BETWEEN XX mars au 30 juin 2023`
2. statut : la télédéclaration doit avoir été validée par son éditeur. `status="SUBMITTED"`
3. année 2022 : `year==2022`
4. `teledeclaration.value_total_ht` non vide


Vous pouvez retrouver l'intégralité du code utilisé sur la page [github de ma-cantine](https://github.com/betagouv/ma-cantine/tree/staging/stats).

```{python Ajout des données cantines pour les td de la campagne 2021}
# | echo: false

def add_canteen_info(df):
    url = f"https://ma-cantine-metabase.cleverapps.io/api/card/820/query/json"
    res = requests.post(
        url,
        headers={
            "Content-Type": "application/json",
            "X-Metabase-Session": os.environ.get("METABASE_TOKEN"),
        },
    )
    td_canteen = pd.DataFrame(res.json())
    col_to_rename = {}
    for col in ["production_type", "management_type", "yearly_meal_count", "daily_meal_count", "sectors"]:
        del df[f"canteen.{col}"]
        col_to_rename[f"{col}"] = f"canteen.{col}"
    td_canteen = td_canteen.rename(columns=col_to_rename)

    df = df.merge(right=td_canteen, left_on="canteen_id", right_on="id")
    return df


def split_td_into_years(td_raw):
    tds = {}
    td = td_raw.copy()
    td = td[td.status == "SUBMITTED"]
    for year in campagnes.keys():
        tds[year] = td.copy()
        tds[year] = tds[year][tds[year].year == int(year)]
        tds[year]["creation_date"] = tds[year]["creation_date"].apply(lambda x: x.split("T")[0])
        tds[year] = tds[year][
            (tds[year]["creation_date"] >= campagnes[year]["start_date"])
            & (tds[year]["creation_date"] <= campagnes[year]["end_date"])
        ]
    tds["2021"] = add_canteen_info(tds["2021"])
    return tds

```

```{python Main}
# | echo: false

tds = {}
columns_of_interest = [
    "teledeclaration.value_bio_ht",
    "teledeclaration.value_total_ht",
    "teledeclaration.value_egalim_others_ht",
    "teledeclaration.value_sustainable_ht",
    "teledeclaration.value_externality_performance_ht",
]

cache=True

if cache:
    for year in campagnes.keys():
        tds[year] = pd.read_csv(f"export_dataset_stats_campagne_{year}.csv", sep=";")
else:
    td_raw = load_td()
    tds = split_td_into_years(td_raw)
    

for year in campagnes.keys():
    # Deleting line terminator substring that could corrupt the backup file
    tds[year]['teledeclaration.other_waste_comments'] = tds[year]['teledeclaration.other_waste_comments'].replace('\r\n', ' ', regex=True).replace('\n', ' ', regex=True)
    # Saving the file
    tds[year].to_csv(f"export_dataset_stats_campagne_{year}.csv", sep=";", index=False)

# Suppression des td non appros
tds["2022"] = tds["2022"].dropna(
    how="all",
    subset=columns_of_interest,
)
```



```{python Vérification des données}
# | echo: false

for year in tds.keys():
    assert (
        tds[year].groupby("canteen_id").size().sort_values(ascending=False).head(1).iloc[0] == 1
    ), "Il y a des doublons de canteen_id"
    assert tds[year]["canteen_id"].isna().sum() == 0, "Il y a des cantines sans identifiant"
    assert len(tds[year]["canteen_id"]) == len(
        tds[year]["canteen_id"].unique()
    ), "Il y a des doublons dans les cantines"
```


## Qualité des données

Avant d'étudier les chiffres clés de la télédéclaration, nous vous présentons des informations sur la disponibilité des données. Ces informations sont importantes pour saisir au mieux la portée des indicateurs.


```{python Vérification du taux de présence de la donnée repas par an}
# | echo: false
# | output: asis

def display_data_coverage(dfs, sub_columns=[], years=[]):
    """
    Takes a dict of DataFrame and display the coverage of data in a markdown table.
    If a subset of columns is given as an argument, only these columns will be take into account
    """
    pourcentage_in_file = {}
    for year in years if len(years) else dfs.keys():
        pourcentage_in_file[year] = {}
        for col in sub_columns if len(sub_columns) else dfs[year].columns:
            col_to_display = col.replace(".", " ").replace("_", " ")
            pourcentage_in_file[year][
                col_to_display
            ] = f"{100 * (1 - dfs[year][col].isna().sum() / len(dfs[year])):.2f} %"

    pourcentage_in_file_to_display = pd.DataFrame(pourcentage_in_file)
    pourcentage_in_file_to_display = pourcentage_in_file_to_display.rename(columns={'2022': 'Part des valeurs non vides (2022)', '2021': 'Part des valeurs non vides (2021)'})
    print(pourcentage_in_file_to_display.to_html())

display_data_coverage(
    tds,
    sub_columns=columns_of_interest,
    years=["2021", "2022"],
)
```

Observons la distribution des valeurs d'achats totaux et des achats bio. Les valeurs étant très différentes entre les différents acteurs (de 0€ à plusieurs millions d'euros déclarés), nous visualisons le logarithme des achats.

```{python}
# | echo: false

import seaborn as sns

col_achats = [
    "teledeclaration.value_bio_ht",
    "teledeclaration.value_total_ht",
]

year = "2022"
for col in col_achats:
    tds[year][col + "_log"] = np.log10(tds[year][[col]].replace(0, 1))

g = sns.displot(tds[year][["teledeclaration.value_bio_ht_log",
    "teledeclaration.value_total_ht_log"]], kde=True)

# Iterate thorugh each axis
for ax in g.axes.flat:
    ax.set_title('Distribution des valeurs d\'achats en € totales et bio', fontsize='large')
    ax.set_ylabel('Nombre de TD', fontsize='large')
    ax.set_xlabel('Valeurs d\'achats en € (en log)', fontsize='large')
g
```

Nous observons une loi log-normale pour les deux valeurs d'achats (une variable peut être modélisée par une loi log-normale si elle est le résultat de la multiplication d'un grand nombre de petits facteurs indépendants).  

A la vue des ces graphiques, nous prenons une **première hypothèse** : *étant possible de réaliser une modélisation, nous estimons que la qualité globale des données de ces champs est bonne. Il existe cependant une légère sur-déclaration de valeurs très faibles (par exemple, nous pouvons nous interroger sur la déclaration de moins de 100€ d'achats bio).*


## Traitement des valeurs manquantes

Nous avons traité de 2 façons différentes les valeurs manquantes.

Ces deux stratégies se concentrent sur les cinq champs de la télédéclaration simplifiée: 

1. `value_bio_ht`
2. `value_total_ht`
3. `value_egalim_others_ht`
4. `value_externality_performance_ht`
5. `value_sustainable_ht`


### Stratégie Historique

La **"stratégie Historique"** (qui a été appliquée sur le premier bilan) : nous remplaçons les valeurs manquantes par la valeur 0, sauf si les 5 champs d'une même déclaration sont vides, auquel cas nous ne prenons pas en compte la ligne
```{python}
# | output: asis
# | echo : false


# TODO : garder value_total dans le dropna ? On supprime peut-etre qq lignes de trop, ou peut etre pas assez !

tds["2022_strat_hist"] = tds["2022"].dropna(
    how="all",
    subset=columns_of_interest,
)

print(f'Après filtrage des lignes dont les 5 champs sont manquants, nous avons gardé **{len(tds["2022_strat_hist"])}** télédéclarations sur les **{len(tds["2022"])}** télédéclarations totales.\n Ensuite nous avons remplaçé par 0 les valeurs manquantes : \n')

achats = {}
for col in columns_of_interest:
    achats[col.replace('teledeclaration.', '')] = tds["2022_strat_hist"][col].isna().sum()

tds["2022_strat_hist"][col_achats] = tds["2022_strat_hist"][col_achats].fillna(0)
df_val_manquantes = pd.DataFrame.from_dict(achats, orient="index").rename(columns={0: "Nombre de valeurs manquantes, remplaçées par 0"})
print(df_val_manquantes.to_markdown())
```

### Stratégie 'Je Ne Sais Pas'

La **"stratégie Je Ne Sais Pas"** : afin de minimiser l'impact des valeurs manquantes, nous supprimons toutes les lignes dès que le champ `teledeclaration.value_bio_ht` est vide. 

Dans les autres cas, comme dans la stratégie 'Historique', nous remplaçons les champs vides par 0.


```{python}
# | output: asis
# | echo: false

for year in ['2021', '2022']:
    tds[f"{year}_strat_2"] = tds[year].dropna(
        how="any",
        subset=[
            "teledeclaration.value_total_ht",
            "teledeclaration.value_bio_ht",
        ],
    )
    if year == '2022':
        print(f'Nous supprimons {len(tds[year]) - len(tds[f"{year}_strat_2"])} lignes car le champ `teledeclaration.value_bio_ht` est vide. \n')
```

# Chiffres clés

```{python Nombre de sites de restauration concernés par la télédéclaration}
# | echo: false
# | output: asis

def calcul_indicateur(tds: {}, years=[]):
    indicateurs = {}
    for year in years if len(years) else tds.keys():
        indicateurs[year] = {}
        indicateurs[year]["Nombre de Télédéclarations"] = len(tds[year])
        indicateurs[year]["Nombre de sites de restauration concernés par la télédéclaration"] = (
            len(tds[year]) + tds[year]["satellite_canteens_count"].sum()
        )
        cuisines_sur_place = tds[year][tds[year]["canteen.production_type"].isin(["site", "site_cooked_elsewhere"])]
        indicateurs[year]["Nombre de cantines sur place (sites et satellites)"] = len(cuisines_sur_place)

        cuisines_centrales = tds[year][tds[year]["canteen.production_type"].isin(["central_serving", "central"])]

        indicateurs[year]["Nombre de repas moyens par jour pour les cantines sur place"] = int(
            cuisines_sur_place["canteen.daily_meal_count"].mean()
        )
        indicateurs[year]["Nombre de repas moyens par jour pour les cantines centrales"] = int(
            cuisines_centrales["canteen.daily_meal_count"].mean()
        )
        indicateurs[year]["Nombre de repas totaux pour l'année"] = int(tds[year]["canteen.yearly_meal_count"].sum())

        indicateurs[year][
            "Répartition du nombre de cantines en gestion directe"
        ] = f"{100 * len(tds[year][tds[year]['canteen.management_type'] == 'direct']) / len(tds[year]):.2f} %"
        indicateurs[year][
            "Répartition du nombre de cantines en gestion concédée"
        ] = f"{100 * len(tds[year][tds[year]['canteen.management_type'] == 'conceded']) / len(tds[year]):.2f} %"
        indicateurs[year][
            "Répartition du nombre de cantines en gestion non renseignée"
        ] = f"{100 * len(tds[year][~tds[year]['canteen.management_type'].isin(['direct', 'conceded'])]) / len(tds[year]):.2f} %"

        indicateurs[year][
            "Montants d'achat alimentaires déclarés"
        ] = f"{int(tds[year]['teledeclaration.value_total_ht'].sum())} €"

        indicateurs[year][
            "Taux global des achats en bio"
        ] = f"{100 * tds[year]['teledeclaration.value_bio_ht'].sum() / tds[year]['teledeclaration.value_total_ht'].sum():.2f} %"

        indicateurs[year][
            "Taux global des achats EGALIM (bio inclus)"
        ] = f"{100 * (tds[year]['teledeclaration.value_egalim_others_ht'].sum() + tds[year]['teledeclaration.value_externality_performance_ht'].sum() + tds[year]['teledeclaration.value_bio_ht'].sum()  + tds[year]['teledeclaration.value_sustainable_ht'].sum()) / tds[year]['teledeclaration.value_total_ht'].sum():.2f} %"

        indicateurs[year]["Nombre de TD ayant déclaré 0€ d'achats en Bio"] = len(
            tds[year][tds[year]["teledeclaration.value_bio_ht"] == 0]
        )
    return indicateurs


indicateurs_to_display = pd.DataFrame(calcul_indicateur(tds, years=["2022_strat_2", "2022_strat_hist"]))
indicateurs_to_display = indicateurs_to_display.rename(columns={'2022_strat_2': 'Données 2022 - Stratégie "Je Ne Sais Pas"', '2022_strat_hist': 'Données 2022 - Stratégie "Historique"'})
print(indicateurs_to_display.to_html())
```

::: info
Pour la suite de l'étude, nous utiliserons uniquement la stratégie **Je Ne Sais Pas** afin de minimiser les hypothèses que nous prenons sur les données.
:::


# Focus par secteurs

Nous nous intéressions à la répartition des télédéclaration en fonction des secteurs principaux et secondaires, pour la campagne sur les données 2022. Nous utilisons la stratégie **Je Ne Sais Pas** pour le traitement des valeurs manquantes.

```{python}
# | echo: false
# | output: asis

def traitement_secteurs(df, year):
    df["canteen.sectors"] = tds[year]["canteen.sectors"].fillna("[]")
    if year != "2021":  # Transform the dict into a list of category
        if cache:
            df["canteen.sectors"] = df["canteen.sectors"].apply(lambda x: ast.literal_eval(x))
        df["canteen.sectors_"] = df["canteen.sectors"].apply(lambda x: [item["name"] for item in x])
    else:
        df["canteen.sectors_"] = df["canteen.sectors"].apply(lambda x: x.split(","))

    # Explode the lists into separate rows
    df_exploded = df.explode("canteen.sectors_")

    # Use get_dummies to create dummy columns for each category
    categories_dummies = pd.get_dummies(df_exploded["canteen.sectors_"])

    # Group by the index (items) and sum the dummy columns

    categories_dummies_grouped = categories_dummies.groupby(by=categories_dummies.index).sum()
    # Concatenate the dummy columns with the original DataFrame
    df_normalized = pd.concat([df, categories_dummies_grouped], axis=1)

    # Drop the 'categories' column since we have the dummies
    df_normalized = df_normalized.drop(columns=["canteen.sectors_"])

    return df_normalized


sectors = {}
for year in ["2022_strat_2"]:
    sectors[year] = {}
    df_processed_sectors = traitement_secteurs(tds[year], year)

    for cat in SECTORS.keys():
        sectors[year][cat] = {}
        df_cat = df_processed_sectors[df_processed_sectors[cat] > 0]
        sectors[year][cat]['Nombre de TD'] = df_cat[cat].sum()
        sectors[year][cat]['% des TD pris en compte'] = f'{100*len(df_cat[cat])/len(tds[year]):.2f} %'
        sectors[year][cat]['Valeur totale des achats'] = df_cat["teledeclaration.value_total_ht"].sum()
        sectors[year][cat]['% achats secteurs'] = f'{100*df_cat["teledeclaration.value_total_ht"].sum()/ tds[year]["teledeclaration.value_total_ht"].sum():.2f} %'
        sectors[year][cat]['Valeur des achats Bio'] = df_cat["teledeclaration.value_bio_ht"].sum()
    summary_by_sector = pd.DataFrame.from_dict(sectors[year]).T

    # Ajout des catégories pour caractériser chaque sous-catégorie
    summary_by_sector['sector'] = summary_by_sector.index.map(SECTORS)
    summary_by_sector = summary_by_sector.reset_index(names='sub_sector')
    summary_by_sector = summary_by_sector.groupby(['sector', 'sub_sector']).sum()
    print(summary_by_sector.to_html())
    print('\n')

```

# Etudes des populations de déclarants

```{python Etablire exactement les cantines ayant participé directement ou indirectement (direct, satellites...)}
# | output: asis
# | echo: false

satellites_sirets = {}
liste_cantines = {}
for year in campagnes.keys():
    df = tds[year]["satellites"].dropna()
    satellites_sirets_raw = df.apply(lambda x: [item["siret"] for item in ast.literal_eval(x)]).values.tolist()
    # Flatten the nested lists into one list with sirets as elements
    satellites_sirets[year] = [item for sublist in satellites_sirets_raw for item in sublist]
    # Uncommnent the line comment to add satellites sirets (only exists for 2022)
    satellites_sirets[year] = tds[year].canteen_siret.values.tolist()  # + satellites_sirets[year]

    # Remove duplicates
    satellites_sirets[year] = list(set(satellites_sirets[year]))

# Télédeclarants présents dans les siret 2022 mais non 2021
entrants = [item for item in satellites_sirets["2022"] if item not in satellites_sirets["2021"]]
print(f"Il y a **{len(entrants)} nouveaux teledeclarants** (ayant déclaré sur la campagne 2023 mais pas celle de 2022)\n")

# Télédeclarants présents dans les siret 2021 mais non 2022
sortants = [item for item in satellites_sirets["2021"] if item not in satellites_sirets["2022"]]
print(
    f"Il y a **{len(sortants)} teledeclarants** n'ayant pas renouvellé (ayant déclaré sur la campagne 2022 mais pas celle de 2023)\n"
)

# Télédéclarants présents lors des deux campagnes
restants = [item for item in satellites_sirets["2021"] if item in satellites_sirets["2022"]]

print(f'Intéressons nous aux autres, que nous appellerons les élèves assidus. Ils sont **{len(restants)} teledeclarants**\n')
```

```{python Echantillon commun}
# | echo: false

tds_commun = {}
for year in ['2021_strat_2', '2022_strat_2']:
    tds_commun[year] = tds[year][tds[year]["canteen.siret"].isin(restants)]

```

## Etude sur échantillon commun - "les élèves assidus"
```{python}
# | output: asis
# | echo: false


indicateurs_to_display = pd.DataFrame(calcul_indicateur(tds_commun, years=['2021_strat_2', '2022_strat_2']))
print(indicateurs_to_display.rename(columns={'2021_strat_2': 'Données 2021', '2022_strat_2': 'Données 2022'}).to_markdown())
```



```{python}
# | echo: false

# Teledeclaration par fichier - Import de masse ?
# Import Source ?
# Qualité données des nouveaux TD
# Nombre de td avec les colonnes remplis (a inclure ds le tableau)
# Restants + nouveaux := 5400 ? ou les 100 ?

```