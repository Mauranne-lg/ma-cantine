---
title: "Bilan statistique de la campagne ma-cantine portant sur l'ann√©e 2023 (travail en cours)"
author:
  - "Quentin Loridant"
  - "Val√©rie Merle"
format:
  html:
    embed-resources: true       
    code-fold: true
    theme:
      - cosmo
    toc: true
    toc-depth: 5
execute:
  warning: false
  cache: false
---

# Introduction

## Contexte

Le bilan statistique annuel de l‚Äôapplication des objectifs d‚Äôapprovisionnement fix√©s √† la restauration collective donne lieu √† un rapport du gouvernement qui est remis au parlement chaque ann√©e.
Celui-ci contient une analyse des donn√©es de la campagne de t√©l√©d√©claration. Le premier bilan est disponible pour la [campagne portant sur les donn√©es 2022](https://1648047458-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-MSCF7Mdc8yfeIjMxMZr%2Fuploads%2F6RxGNr0aJ4BPSzFsDQGs%2FBilan%20statistique%20EGAlim_achats2022.pdf?alt=media&token=).

Dans ce document nous cr√©ons et documentons les statistiques n√©cessaires pour la campagne ayant eu lieu sur le premier semestre 2023 et portant sur les donn√©es de l'ann√©e 2023.


```{python import}
# | echo: false
import pandas as pd
import numpy as np
import ast
import datetime
from ydata_profiling import ProfileReport
import psycopg2
import plotly.express as px
import matplotlib.pyplot as plt
from matplotlib import dates as mdates
import locale
import utils
```

<!-- Afin de r√©cup√©rer les donn√©es, il vous faut un TOKEN metabase :
`curl -X POST -H "Content-Type: application/json" -d '{"username": <USERNAME>, "password": <PASSWORD>}' https://ma-cantine-metabase.cleverapps.io/api/session` -->

Les donn√©es sont extraites de la base de donn√©es de ma-cantine. Plusieurs filtres sont appliqu√©s :

1. date : les t√©l√©d√©clarations doivent √™tre comprises dans les dates de campagne: `creation_date ENTRE 13 f√©vrier au 30 juin 2023`
2. statut : la t√©l√©d√©claration doit avoir √©t√© valid√©e par son √©diteur. `status="SUBMITTED"`
3. ann√©e 2023 : `year==2023`
4. `teledeclaration.value_total_ht` non vide*
5. Filtrage des TD dont les montants t√©l√©dacalr√©s sont aberrants > 


Vous pouvez retrouver l'int√©gralit√© du code utilis√© sur la page [github de ma-cantine](https://github.com/betagouv/ma-cantine/tree/staging/stats).

```{python Main}
# | echo: false

cache=True

if not cache:
    tds = utils.load_td()
    
    for year in utils.CAMPAGNES.keys():
        # Saving the file 
        tds[year].to_csv(f"data/export_dataset_stats_campagne_{year}.csv", sep=';', index=False)
        
        # Application de la strat√©gie Je Ne Sais pas
        tds[f"Campagne {year}"] = tds[year].dropna(
            how="any",
            subset=[
                "teledeclaration.value_total_ht",
                "teledeclaration.value_bio_ht",
            ],
        )
        utils.TUNNEL_DATA_ENG[year]['Apr√®s application strat√©gie Je Ne Sais Pas'] = len(tds[f'Campagne {year}'])

        tds[f"strat_max_{year}"] = tds[year].dropna(
            how="any",
            subset=[
            "teledeclaration.value_bio_ht",
            "teledeclaration.value_total_ht",
            "teledeclaration.value_egalim_others_ht",
            "teledeclaration.value_sustainable_ht",
            "teledeclaration.value_externality_performance_ht",
            ],
        )
        tds[f"{year}_strat_hist"] = tds[year].dropna(
            how="all",
            subset=utils.APPRO_SIMPLIFIED,
        )

        # Saving the file strat√©gie Je Ne Sais Pas
        tds[f"Campagne {year}"].to_csv(f"data/export_dataset_stats_campagne_clean_{year}.csv", sep=';', index=False)

        # Saving the file strat√©gie Historique
        tds[f"{year}_strat_hist"].to_csv(f"data/export_dataset_stats_campagne_hist_{year}.csv", sep=';', index=False)

        # Saving the file strat√©gie Max
        tds[f"strat_max_{year}"].to_csv(f"data/export_dataset_stats_campagne_max_{year}.csv", sep=';', index=False)


# Whether we use cache or ot, we re-read the file to have consistency in the dataframe
tds={}
for year in utils.CAMPAGNES.keys():
    tds[year] = pd.read_csv(f"data/export_dataset_stats_campagne_{year}.csv", sep=";")
    tds[f"Campagne {year}"] = pd.read_csv(f"data/export_dataset_stats_campagne_clean_{year}.csv", sep=";")
    tds[f"{year}_strat_hist"] = pd.read_csv(f"data/export_dataset_stats_campagne_hist_{year}.csv", sep=";")
    tds[f"strat_max_{year}"] = pd.read_csv(f"data/export_dataset_stats_campagne_max_{year}.csv", sep=";")


# D√©finition des populations assidus, entrantes et sortantes
td_pop = {}
td_pop['2023'] = list(set(tds['Campagne 2023']['canteen.id'].values.tolist())) 
td_pop['2022'] = list(set(tds['Campagne 2022']['canteen.id'].values.tolist())) 
# T√©l√©declarants pr√©sents dans les siret 2023 mais non 2022
entrants = list(set([item for item in td_pop['2023'] if item not in td_pop['2022']]))
tds['Campagne 2023'][tds['Campagne 2023']['canteen.id'].isin(entrants)].to_csv('data/entrants.csv', sep=';', index=False)

# T√©l√©declarants pr√©sents dans les siret 2022 mais non 2023
sortants = list(set([item for item in td_pop['2022'] if item not in td_pop['2023']]))
tds['Campagne 2022'][tds['Campagne 2022']['canteen.id'].isin(sortants)].to_csv('data/sortants.csv', sep=';', index=False)

# T√©l√©d√©clarants pr√©sents lors des deux campagnes
restants = [item for item in td_pop['2022'] if item in td_pop['2023']]

tds_commun = {}
for year in ['2022', '2023', 'Campagne 2022', 'Campagne 2023', '2022_strat_hist', '2023_strat_hist']:
    tds_commun[year] = tds[year][tds[year]["canteen.id"].isin(restants)]
    tds_commun[year] = tds_commun[year].drop_duplicates('canteen.id')

if not cache:
    utils.TUNNEL_DATA_ENG['2023']['Apr√®s s√©l√©ction des assidus'] = len(tds_commun['2023'])


# Filtrage des assidus dont les montants d√©clar√©s entre les 2 campganes sont trop diff√©rents
iso = tds_commun['Campagne 2023'].merge(tds_commun['Campagne 2022'], on='canteen.id', suffixes=('_2023', '_2022'))
iso['evo_montant_achats'] = iso['teledeclaration.value_total_ht_2023'] / iso['teledeclaration.value_total_ht_2022']
iso = iso[iso['evo_montant_achats'] < 2]
iso = iso[iso['evo_montant_achats'] > 0.5]
asssidus_clean = list(iso['canteen.id'])

for year in ['2022', '2023', 'Campagne 2022', 'Campagne 2023', '2022_strat_hist', '2023_strat_hist']:
    tds_commun[year] = tds_commun[year][tds_commun[year]['canteen.id'].isin(asssidus_clean)]
    tds_commun[year].to_csv(f'data/assidus_{year}.csv', sep=';', index=False)

if not cache:
    utils.TUNNEL_DATA_ENG['2023']['Apr√®s filtrage des assidus'] = len(tds_commun['2023'])

```


## Qualit√© des donn√©es

Avant d'√©tudier les chiffres cl√©s de la t√©l√©d√©claration, nous vous pr√©sentons des informations sur la disponibilit√© des donn√©es. Ces informations sont importantes pour saisir au mieux la port√©e des indicateurs.

### Traitements sur les TD 2023
```{python}
if not cache:
    df = pd.DataFrame(utils.TUNNEL_DATA_ENG['2023'].values(), index=utils.TUNNEL_DATA_ENG['2023'].keys(), columns=['values'])

    with plt.style.context("fivethirtyeight"):
        fig = plt.figure(figsize=(3, 9))

        # y_values = [11, 9, 7, 5, 3, 1]  # Adjust these values for your desired positioning
        y_values = [1, 3, 5, 7, 9, 11, 13]  # Adjust these values for your desired positioning
        
        x1 = 18  # Adjust the starting x1 position
        x2 = 0   # Adjust the starting x2 position
        offset = 1
        for i in range(len(y_values)):
            if i == 0 or i == 2:
                color = "dodgerblue"
            else:
                color = "purple"

            plt.fill_betweenx(y=[y_values[i], y_values[i] - 1], x1=[x1, x1], x2=[x2, x2], color=color)
            plt.fill_betweenx(y=[y_values[i] - 1, y_values[i] - 2], x1=[x1, x1 - offset], x2=[x2, x2 + offset], color=color, alpha=0.5)
            offset = 1 if i !=1 else 6
            x1 += offset  # Adjust the next x1 position
            x2 += - offset  # Adjust the next x2 position

        plt.yticks([y_values[i] - 0.5 for i in range(len(y_values))], df.index[::-1])
        plt.xticks([], [])

        for i, val in enumerate(df["values"][::-1]):
            plt.text(9, y_values[i] - 0.5, val, ha="center", fontsize=16, fontweight="bold", color="white")

        plt.grid(visible=False)
        plt.title("Traitement des t√©l√©d√©clarations", loc="right", fontsize=25, fontweight="bold")
        plt.show()

```


### üì∑ Campagne 2022

```{python V√©rification du taux de pr√©sence de la donn√©e repas par an}
# | echo: false
# | output: asis

utils.assert_quality(tds)

utils.display_data_coverage(
    tds,
    sub_columns=utils.APPRO_SIMPLIFIED,
    years=["2022"],
)
```

### üì∑ Campagne 2023

```{python V√©rification du taux de pr√©sence de la donn√©e repas par an}
# | echo: false
# | output: asis

utils.assert_quality(tds)

utils.display_data_coverage(
    tds,
    sub_columns=utils.APPRO_SIMPLIFIED,
    years=["2023"],
)
```

### ‚öñÔ∏è Comparaison isop√©rim√®tre

```{python V√©rification du taux de pr√©sence de la donn√©e repas par an}
# | echo: false
# | output: asis

utils.assert_quality(tds)

utils.display_data_coverage(
    tds_commun,
    sub_columns=utils.APPRO_SIMPLIFIED,
    years=["2022", "2023"],
)
```

Observons la distribution des valeurs d'achats totaux et des achats bio. Les valeurs √©tant tr√®s diff√©rentes entre les diff√©rents acteurs (de 0‚Ç¨ √† plusieurs millions d'euros d√©clar√©s), nous visualisons le logarithme des achats.

```{python}
# | echo: false

import seaborn as sns

col_achats = [
    "teledeclaration.value_bio_ht",
    "teledeclaration.value_total_ht",
]

year = "2023"
for col in col_achats:
    tds[year][col + "_log"] = np.log10(tds[year][[col]].replace(0, 1))

g = sns.displot(tds[year][["teledeclaration.value_bio_ht_log",
    "teledeclaration.value_total_ht_log"]], kde=True)

# Iterate thorugh each axis
for ax in g.axes.flat:
    ax.set_title('Distribution des valeurs d\'achats en ‚Ç¨ totales et bio', fontsize='large')
    ax.set_ylabel('Nombre de TD', fontsize='large')
    ax.set_xlabel('Valeurs d\'achats en ‚Ç¨ (en log)', fontsize='large')
g
```

Nous observons une loi log-normale pour les deux valeurs d'achats (une variable peut √™tre mod√©lis√©e par une loi log-normale si elle est le r√©sultat de la multiplication d'un grand nombre de petits facteurs ind√©pendants).  

A la vue des ces graphiques, nous prenons une **premi√®re hypoth√®se** : *√©tant possible de r√©aliser une mod√©lisation, nous estimons que la qualit√© globale des donn√©es de ces champs est bonne. Il existe cependant une l√©g√®re sur-d√©claration de valeurs tr√®s faibles (par exemple, nous pouvons nous interroger sur la d√©claration de moins de 100‚Ç¨ d'achats bio).*


## Traitement des valeurs manquantes

Nous avons trait√© de 2 fa√ßons diff√©rentes les valeurs manquantes : **strat√©gie historique** et **strat√©gie Je Ne Sais Pas**.

Ces deux strat√©gies se concentrent sur les cinq champs de la t√©l√©d√©claration simplifi√©e: 

1. `value_bio_ht`
2. `value_total_ht`
3. `value_egalim_others_ht`
4. `value_externality_performance_ht`
5. `value_sustainable_ht`


### Strat√©gie Historique

La **"strat√©gie Historique"** (qui a √©t√© appliqu√©e sur le premier bilan) : nous rempla√ßons les valeurs manquantes par la valeur 0, sauf si les 5 champs d'une m√™me d√©claration sont vides, auquel cas nous ne prenons pas en compte la ligne

```{python}
# | output: asis
# | echo : false


valeurs_manquantes = {}
valeurs_manquantes_iso_perim = {}
for year in utils.CAMPAGNES.keys():
    valeurs_manquantes[year] = {}
    valeurs_manquantes_iso_perim[year] = {}
    for col in utils.APPRO_SIMPLIFIED:
        valeurs_manquantes[year][col.replace('teledeclaration.', '')] = tds[f"{year}_strat_hist"][col].isna().sum()    
        valeurs_manquantes_iso_perim[year][col.replace('teledeclaration.', '')] = tds_commun[f"{year}_strat_hist"][col].isna().sum()    


def display_data_coverage(year):
    print(f'Apr√®s filtrage des lignes dont les 5 champs sont manquants, nous avons gard√© **{len(tds[f"{year}_strat_hist"])}** t√©l√©d√©clarations sur les **{len(tds[year])}** t√©l√©d√©clarations totales.\n Ensuite nous avons rempla√ß√© par 0 les valeurs manquantes : \n')
    utils.display_indicateurs(pd.DataFrame.from_dict(valeurs_manquantes[year], orient="index").rename(columns={0: "Nombre de valeurs manquantes, rempla√ß√©es par 0"}))
```

#### üì∑ 2022

```{python}
# | output: asis
# | echo : false
display_data_coverage('2022')
```

#### üì∑ 2023
```{python}
# | output: asis
# | echo : false
display_data_coverage('2023')
```

#### ‚öñÔ∏è Comparaison isop√©rim√®tre
```{python}
# | output: asis
# | echo : false
utils.display_indicateurs(pd.DataFrame.from_dict(valeurs_manquantes_iso_perim).rename(columns={'2022': "2022 : Nombre de valeurs manquantes, rempla√ß√©es par 0", '2023': '2023 : Nombre de valeurs manquantes, rempla√ß√©es par 0'}))
```
### Strat√©gie 'Je Ne Sais Pas'

La **"strat√©gie Je Ne Sais Pas"** : afin de minimiser l'impact des valeurs manquantes, nous supprimons toutes les lignes d√®s que le champ `teledeclaration.value_bio_ht` est vide. 

Dans les autres cas, comme dans la strat√©gie 'Historique', nous rempla√ßons les champs vides par 0.

#### üì∑ 2022
```{python}
# | output: asis
# | echo: false

year = '2022'
print(f'Nous supprimons {len(tds[year]) - len(tds[f"Campagne {year}"])} lignes car le champ `teledeclaration.value_bio_ht` est vide. \n')
```

#### üì∑ 2023
```{python}
# | output: asis
# | echo: false

year = '2023'
print(f'Nous supprimons {len(tds[year]) - len(tds[f"Campagne {year}"])} lignes car le champ `teledeclaration.value_bio_ht` est vide. \n')
```
#### ‚öñÔ∏è Comparaison isop√©rim√®tre
```{python}
# | output: asis
# | echo: false

indic = {}
for year in utils.CAMPAGNES.keys():
    indic[year] = len(tds_commun[year]) - len(tds_commun[f"Campagne {year}"])

utils.display_indicateurs(pd.DataFrame.from_dict(indic, orient='index').rename(columns={0: 'teledeclaration.value_bio_ht'}).T.rename(columns={'2022': "2022 : Nombre de valeurs manquantes, rempla√ß√©es par 0", '2023': '2023 : Nombre de valeurs manquantes, rempla√ß√©es par 0'}))
```

### Strat√©gie Maximale
La strat√©gie maximale permet d'√©tablir le haut de la fourchette pour le taux d'achats EGALIM.
Pour ce faire,  nous avons gard√© uniquement les TD dont tous les champs appros ont √©t√© remplis.


# Chiffres cl√©s

## üì∑ 2022
### Chiffre g√©n√©raux
```{python Nombre de sites de restauration concern√©s par la t√©l√©d√©claration}
# | echo: false
# | output: asis

indic_divers, indic_appro = utils.calcul_indicateur(tds, years=["Campagne 2022", "2022_strat_hist", "Campagne 2023", "2023_strat_hist", "strat_max_2023"])

indic_divers = indic_divers.rename(columns={'Campagne 2022': 'Campagne 2022 - Strat√©gie "Je Ne Sais Pas"', '2022_strat_hist': 'Campagne 2022 - Strat√©gie "Historique"', 'Campagne 2023': 'Campagne 2023 - Strat√©gie "Je Ne Sais Pas"', '2023_strat_hist': 'Campagne 2023 - Strat√©gie "Historique"', 'strat_max_2023': 'Campagne 2023 - Strat√©gie Maximale'})

utils.display_indicateurs(indic_divers[['Campagne 2022 - Strat√©gie "Je Ne Sais Pas"', 'Campagne 2022 - Strat√©gie "Historique"']])
```

### Chiffres appro
```{python Nombre de sites de restauration concern√©s par la t√©l√©d√©claration}
# | echo: false
# | output: asis
indic_appro = indic_appro.rename(columns={'Campagne 2022': 'Campagne 2022 - Strat√©gie "Je Ne Sais Pas"', '2022_strat_hist': 'Campagne 2022 - Strat√©gie "Historique"', 'Campagne 2023': 'Campagne 2023 - Strat√©gie "Je Ne Sais Pas"', '2023_strat_hist': 'Campagne 2023 - Strat√©gie "Historique"', 'strat_max_2023': 'Campagne 2023 - Strat√©gie Maximale'})
utils.display_indicateurs(indic_appro[['Campagne 2022 - Strat√©gie "Je Ne Sais Pas"', 'Campagne 2022 - Strat√©gie "Historique"']])
```

## üì∑ 2023
### Chiffre g√©n√©raux
```{python Nombre de sites de restauration concern√©s par la t√©l√©d√©claration}
# | echo: false
# | output: asis

utils.display_indicateurs(indic_divers[['Campagne 2023 - Strat√©gie "Je Ne Sais Pas"', 'Campagne 2023 - Strat√©gie "Historique"', "Campagne 2023 - Strat√©gie Maximale"]])
```

### Chiffres appro
```{python Nombre de sites de restauration concern√©s par la t√©l√©d√©claration}
# | echo: false
# | output: asis

utils.display_indicateurs(indic_appro[['Campagne 2023 - Strat√©gie "Je Ne Sais Pas"', 'Campagne 2023 - Strat√©gie "Historique"', "Campagne 2023 - Strat√©gie Maximale"]])
```

## ‚öñÔ∏è Comparaison isop√©rim√®tre

### Chiffres g√©n√©raux

```{python}
# | echo: false
# | output: asis


indic_divers, indic_appro = utils.calcul_indicateur(tds_commun, years=["Campagne 2022", "Campagne 2023"])

# Table view
utils.display_indicateurs(indic_divers)

# Graph view
df_indic_divers = pd.DataFrame(indic_divers)
df_indic_appro = pd.DataFrame(indic_appro)

# Isolate the values with numbers
divers_colonnes_nombre = ['Nombre de cantines centrales',  'Nombre de cantines sur place (sites et satellites)', 'Nombre de T√©l√©d√©clarations']

utils.display_stacked_bars(df_indic_divers.T[divers_colonnes_nombre].T, title='Comparaison des profils',  fmt=utils.nombre_formatter)

# Isolate the values with ratios
divers_colonnes_ratios = ['Taux de TD d√©taill√©es']

utils.display_stacked_bars(df_indic_divers.T[divers_colonnes_ratios].T, title='Comparaison des profils', fmt=utils.taux_formatter)
```

### Chiffres appro
```{python}
# | echo: false
# | output: asis

# Isolate the values with numbers
appro_colonnes_montants = ['Montant d\'achat alimentaires bio', 'Montant d\'achat alimentaires EGALIM (bio inclus)', 'Montant d\'achat alimentaires total', "Montant des achats alimentaires cuisines centrales", "Montant des achats alimentaires cantines satellites"]
utils.display_indicateurs(indic_appro)
utils.display_stacked_bars(df_indic_appro.T[appro_colonnes_montants].T, title='Comparaison des montants alimentaires d√©pens√©s',  fmt=utils.montant_formatter)

# Isolate the values with ratios
appro_colonnes_taux = ['Taux global des achats en bio',  'Taux global des achats EGALIM (bio inclus)']
utils.display_stacked_bars(df_indic_appro.T[appro_colonnes_taux].T, title='Comparaison des ratios sur les montants',  fmt=utils.taux_formatter)
```

::: {.callout-note}
Pour la suite de l'√©tude, nous utiliserons uniquement la strat√©gie "**Je Ne Sais Pas**"" afin de minimiser les hypoth√®ses que nous prenons sur les donn√©es.
:::

# Chiffres par famille de produits
::: {.callout-warning}
Pour le moment, ces chiffres ne d√©crivent que les t√©l√©d√©clarations de type simplifi√©es. L'ajout de t√©l√©d√©claration compl√®tes est en cours. A priori, les ratio devraient cependant rester sembables.
:::

::: {.callout-note}
:::
## üì∑ 2023

```{python Nombre de sites de restauration concern√©s par la t√©l√©d√©claration}
# | echo: false
# | output: asis
col_order = [
    "Nombre de TD prises en compte",
    "Nombre de TD ayant d√©clar√© pour la famille Viande/Volaille ü•©",
    "Nombre de TD ayant d√©clar√© la valeur 0‚Ç¨ pour la famille Viande/Volaille ü•©",
    "Montant des achats alimentaires totaux pour la famille Viande/Volaille ü•©",
    "Taux d'achat alimentaires de la famille Viande/Volaille ü•©",
    "Montant d'achat alimentaires Viande/Volaille ü•©",
    "Taux d'achat alimentaires Egalim au sein de la famille Viande/Volaille ü•©",
    "Montant d'achat alimentaires Egalim Viande/Volaille ü•©",
    "Taux d'achat alimentaires origine France üá´üá∑ au sein de la famille Viande/Volaille ü•©",
    "Montant d'achat alimentaires origine France üá´üá∑ Viande/Volaille ü•©",
    "Nombre de TD ayant d√©clar√© pour la famille Poissons/Produits de la mer üêü",
    "Nombre de TD ayant d√©clar√© la valeur 0‚Ç¨ pour la famille Poissons/Produits de la mer üêü",
    "Montant des achats alimentaires totaux pour la famille Poissons/Produits de la mer üêü",
    "Taux d'achat alimentaires de la famille Poissons/Produits de la mer üêü",
    "Taux d'achat alimentaires Egalim au sein de la famille Poissons/Produits de la mer üêü",
    "Montant d'achat alimentaires Poissons/Produits de la mer üêü",
    "Montant d'achat alimentaires Egalim Poissons/Produits de la mer üêü"
]

indic_famille = utils.calcul_indicateur_famille(tds, years=["Campagne 2023"])
utils.display_indicateurs(indic_famille['Campagne 2023'][col_order])
indic_famille['Campagne 2023'][col_order].to_excel('data/Photo-2023-familles.xlsx')
```

## Comparaison isop√©rimetrique

```{python Nombre de sites de restauration concern√©s par la t√©l√©d√©claration}
# | echo: false
# | output: asis
indic_famille = utils.calcul_indicateur_famille(tds_commun, years=["Campagne 2022", "Campagne 2023"])
indic_famille = utils.ajout_col_comparaison(indic_famille)
utils.display_indicateurs(indic_famille)
indic_famille['Campagne 2023'].to_excel('data/isoperimetre-familles.xlsx')

```

# R√©partition des t√©l√©d√©clarants par taille de cantines
## üì∑ 2023
```{python}

def categorisation_taille(x):
    if x <= 200:
        return 'Inf√©rieur ou √©gal √† 200'
    elif 200 < x <= 700:
        return 'De 200 √† 700'
    elif 700 < x <= 1500:
        return 'De 700 √† 1500'
    elif x > 1500:
        return 'Sup√©rieur √† 1500'
    else: 
        return 'Taille inconnue'

year = 'Campagne 2023'
df_taille = tds[year].copy()[['canteen.id', 'canteen.daily_meal_count']]
df_taille = df_taille.sort_values('canteen.daily_meal_count')
df_taille['Taille'] = df_taille['canteen.daily_meal_count'].apply(lambda x: categorisation_taille(x))
ax = sns.histplot(df_taille['Taille'])
plt.xticks(rotation=60)
ax.patches[-1].set_facecolor('salmon')   
ax.set_ylabel('Nombre de t√©l√©d√©clarations',)
ax.set_title('Distribution des t√©l√©d√©clarants en fonction de la taille des cantines \n(bas√© sur le nombre de repas servis par jour)')
   
df_taille = df_taille.groupby('Taille').count()[['canteen.id']].rename(columns={'canteen.id': 'Nombre'})
taille_totale = len(tds[year])
df_taille['Pourcentage'] = df_taille.apply(lambda x: utils.taux_formatter(x['Nombre']/taille_totale), axis=1)
```

```{python Co√ªt denr√©es}
# | echo: false
# | output: asis

# Cout denr√©es - Donn√©es Aberrantes
df = tds['Campagne 2023'].copy()
errors = df[(df['teledeclaration.cout_denrees'] > 10) | (((df['teledeclaration.cout_denrees'] > 0) & (df['teledeclaration.cout_denrees'] < 1.5)))]
errors = errors.sort_values('teledeclaration.cout_denrees', ascending=False)
errors.to_csv('data/cout_denrees_errors.csv', sep=';', index=False)
errors.to_html()
```

{{< include _secteurs.qmd >}}
{{< include _populations.qmd >}}
{{< include _geo.qmd >}}


# Evolution des t√©l√©d√©claration lors de la campagne 2023
```{python}
df = tds['Campagne 2023']
def categorize_taux_bio(row):
    taux = 100 * row['teledeclaration.value_bio_ht'] / row['teledeclaration.value_total_ht']
    return taux

def categorize_taux_egalim(row):
    taux = 100 * (row["teledeclaration.value_egalim_others_ht"]
            + row["teledeclaration.value_externality_performance_ht"]
            + row["teledeclaration.value_bio_ht"]
            + row["teledeclaration.value_sustainable_ht"]) / row['teledeclaration.value_total_ht']
    return taux
df['Distribution des taux Bio'] = df.apply(categorize_taux_bio , axis=1)
df['Distribution des taux Egalim'] = df.apply(categorize_taux_egalim , axis=1)


g = sns.displot(df, x='Distribution des taux Bio', bins=20)
for i, ax in enumerate(g.axes[:, 0]):
    ax.set_ylabel('Nombre de t√©l√©d√©clarations',)
    ax.axvline(x = 20,      # Line on x = 2
           ymin = 0, # Bottom of the plot
           ymax = 0.8,
           color='green',
           linestyle = "dashed",
           lw=4) # Top of the plot
    ax.text(25,1300,'Objectif : 20%', color='green')
g = sns.displot(df, x='Distribution des taux Egalim', bins=20)
for i, ax in enumerate(g.axes[:, 0]):
    ax.set_ylabel('Nombre de t√©l√©d√©clarations',)
    ax.axvline(x = 50,      # Line on x = 2
        ymin = 0, # Bottom of the plot
        ymax = 0.8,
        color='purple',
        linestyle = "dashed", lw=4) # Top of the plot
    ax.text(55,150,'Objectif : 50%', color='purple')
```

## Nombre de t√©l√©d√©clarations ayant rempli les objectifs bio et Egalim

```{python}
# | echo: false
# | output: asis
df = tds['Campagne 2023'].copy()
df = df[df['Distribution des taux Bio'] >= 20]
print(f'{len(df)} t√©l√©d√©clarants remplissent les objectifs Bio\n')
df = tds['Campagne 2023'].copy()
df = df[df['Distribution des taux Egalim'] >= 50]
print(f'{len(df)} t√©l√©d√©clarants remplissent les objectifs Egalim\n')
df = tds['Campagne 2023'].copy()
df = df[df['Distribution des taux Bio'] >= 20]
df = df[df['Distribution des taux Egalim'] >= 50]
print(f'{len(df)} t√©l√©d√©clarants remplissent les objectifs Bio et Egalim')
```