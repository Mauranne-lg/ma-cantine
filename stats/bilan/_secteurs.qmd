
# Focus par secteurs

Nous nous intéressions à la répartition des télédéclaration en fonction des secteurs principaux et secondaires, pour la campagne sur les données 2022. Nous utilisons la stratégie **Je Ne Sais Pas** pour le traitement des valeurs manquantes.

::: {.callout-note}
Les cuisines centrales ont été supprimées car elles cumulent plusieurs secteurs (`central` et `central_serving`)
:::

## Focus sur les catégories principales
```{python}
# | echo: false
# | output: asis

def traitement_secteurs(df, year):
    df["canteen.sectors"] = tds[year]["canteen.sectors"].fillna("[]")
    if year != "2021":  # Transform the dict into a list of category
        df["canteen.sectors"] = df["canteen.sectors"].apply(lambda x: ast.literal_eval(x))
        df["canteen.sectors_"] = df["canteen.sectors"].apply(lambda x: [item["name"] for item in x])
    else:
        df["canteen.sectors_"] = df["canteen.sectors"].apply(lambda x: x.split(","))

    # Explode the lists into separate rows
    df_exploded = df.explode("canteen.sectors_")

    # Use get_dummies to create dummy columns for each category
    categories_dummies = pd.get_dummies(df_exploded["canteen.sectors_"])

    # Group by the index (items) and sum the dummy columns

    categories_dummies_grouped = categories_dummies.groupby(by=categories_dummies.index).sum()
    # Concatenate the dummy columns with the original DataFrame
    df_normalized = pd.concat([df, categories_dummies_grouped], axis=1)

    # Drop the 'categories' column since we have the dummies
    df_normalized = df_normalized.drop(columns=["canteen.sectors_"])

    return df_normalized

sectors = {}
year ="2022_strat_2"
sectors[year] = {}
df_processed_sectors = traitement_secteurs(tds[year], year)
df_processed_sectors = df_processed_sectors[~df_processed_sectors['canteen.production_type'].isin(['central', 'central_serving'])]
for cat in utils.SECTORS.keys():
    sectors[year][cat] = {}
    df_cat = df_processed_sectors[df_processed_sectors[cat] > 0]
    sectors[year][cat]['Nombre de TD'] = df_cat[cat].sum()
    sectors[year][cat]['Taux des TD pris en compte'] = len(df_cat[cat])/len(tds[year])
    sectors[year][cat]['Montant total des achats'] = df_cat["teledeclaration.value_total_ht"].sum()
    sectors[year][cat]['Taux des achats Bio'] = df_cat["teledeclaration.value_bio_ht"].sum()/df_cat["teledeclaration.value_total_ht"].sum()
    sectors[year][cat]['Montant des achats Bio'] = df_cat["teledeclaration.value_bio_ht"].sum()
    sectors[year][cat]['Taux achats secteurs'] = df_cat["teledeclaration.value_total_ht"].sum()/ tds[year]["teledeclaration.value_total_ht"].sum()

summary = pd.DataFrame.from_dict(sectors[year]).T

# Ajout des catégories pour caractériser chaque sous-catégorie
summary['sector'] = summary.index.map(utils.SECTORS)
summary = summary.reset_index(names='sub_sector')

# Calcul des totaux par secteurs
summary_by_sector = summary.groupby(['sector']).sum()
summary_by_sector['sub_sector'] = ['Total (somme)'] * len(summary_by_sector)
summary_by_sector = summary_by_sector.reset_index(names='sector')

# Agregation des sous secteur et secteurs
summary_by_sub_sector = pd.concat([summary, summary_by_sector])
summary_by_sub_sector = summary_by_sub_sector.groupby(['sector', 'sub_sector']).sum()

# TODO  A optimiser : Actuellement nous recalculons tous les taux car ils ont été corrompus par l'aggrégation en somme
summary_by_sub_sector['Taux des achats Bio'] = summary_by_sub_sector.apply(lambda x: x['Montant des achats Bio'] / x['Montant total des achats'], axis=1)
summary_by_sub_sector['Taux achats secteurs'] = summary_by_sub_sector.apply(lambda x: x['Montant total des achats'] / tds[year]["teledeclaration.value_total_ht"].sum(), axis=1)

utils.display_indicateurs(summary_by_sub_sector, transpose=False)
print('\n')
```
