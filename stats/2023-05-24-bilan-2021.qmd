---
title: "Ma-Cantine : Reconstruction des statistiques du bilan 2021"
author:
  - "Quentin Loridant"
date: "2023-05-24"
format:
  html:
    embed-resources: true
    code-fold: true
    theme:
      - readable
    toc: true
    toc-depth: 2
execute:
  cache: true
---

# Contexte
Analyse des données de la campagne de TD 2022.

* En 2021, l'application ne permettait pas de spécifier le mode de télédéclaration.  
* La campagne de 2022 porte sur les données de 2021  
* Les données sont issus d'une extractation de la base de données de l'application Ma-Cantine, en filtrant sur :
    * l'année 2021
    * les données de type 'SUBMITTED'
    * les `creation_date` qui sont compris dans les dates de la campagne : **du 17 juillet 2022 au 05 décembre 2022**. (les autres TD de 2021 avant la campagne sont dans un format trop différent pour être traité)
    * Les canteen ID qui sont renseignés (champs non nuls)


# Import des données et des librairies
```{python import}
import pandas as pd
import os
import datetime
import requests
import json
from dotenv import load_dotenv
from ydata_profiling import ProfileReport

```
```{python Import des données des campagnes}
campagnes = {
  "2021": "795",
  "2022": "802"
}
```

Afin de récupérer les données, il vous faut un TOKEN metabase :  
`curl -X POST -H "Content-Type: application/json" -d '{"username": <USERNAME>, "password": <PASSWORD>}' https://ma-cantine-metabase.cleverapps.io/api/session`

```{python Import des données TD}
year = '2022'
url = f"https://ma-cantine-metabase.cleverapps.io/api/card/{campagnes[year]}/query/json"

load_dotenv()

header = {
    "Content-Type": "application/json",
    "X-Metabase-Session": os.getenv("METABASE_TOKEN"),
}

res = requests.post(
    url,
    headers=header,
)
td = pd.DataFrame(res.json())
td["declared_data"] = td["declared_data"].apply(json.loads)
td_json = pd.json_normalize(td["declared_data"])
td = pd.concat([td.drop("declared_data", axis=1), td_json], axis=1)

if year == '2021':
    col_to_rename = {}
    for col in ['production_type', 'management_type', 'yearly_meal_count', 'daily_meal_count']:
        col_to_rename[col] = f"canteen.{col}"
    td = td.rename(columns=col_to_rename)
```


# Nettoyage et formattage des données
```{python Nettoyage des données}
nbre_td_full = len(td)
td = td.dropna(subset=["canteen_id"])
print(f"Nous avons enlevé {nbre_td_full - len(td)} doublons")
print("Nombre de télédcélarations uniques: ", len(td))
```


# Vérifications de la qualité des données
```{python Vérification des données}
td.groupby("canteen_id").size().sort_values(ascending=False).head(10)
td = td[td.id != 10871] # Doublon inexpliqué entre les id 10871 et 10870
```

```{python Vérification des données}
assert td["canteen_id"].isna().sum() == 0, "Il y a des cantines sans identifiant"
assert len(td["canteen_id"]) == len(td["canteen_id"].unique()), "Il y a des doublons dans les cantines"
# for col in td.columns:
#     print(col)
```

# Comparaison avec les données du rapport
<!-- ```{python Verification des valeurs en recréant l'erreur}
td_to_keep = pd.read_csv('stats/canteen_id_rapport.csv')
td = td[td['canteen_id'].isin(td_to_keep['canteen_id'])]
``` -->

# Chiffres clés
```{python Nombre de Télédéclarations}
indicateurs = {}
indicateurs["Nombre de Télédéclarations"] = len(td)
```

Dans les télédéclarations pour la campagne 2022, il n'y a pas d'indication du nombre de satellites, du managment_type et du produciton_type. 

Les informations suivanted proviennent donc des informations renseignées pour les cantines. Les données ont peut-être légérement été modifié depuis la télédéclaration.

```{python Nombre de sites de restauration concernés par la télédéclaration}
indicateurs["Nombre de sites de restauration concernés par la télédéclaration"] = (
    len(td) + td["satellite_canteens_count"].sum()
)
cuisines_sur_place = td[td["canteen.production_type"].isin(["site", "site_cooked_elsewhere"])]
indicateurs["Nombre de cantines sur place (sites et satellites)"] = len(cuisines_sur_place)

cuisines_centrales = td[td["canteen.production_type"].isin(["central_serving", "central"])]
indicateurs["Nombre de cantines centrales"] = len(cuisines_centrales)

indicateurs["Nombre de repas moyens par jour pour les cantines sur place"] = int(
    cuisines_sur_place["canteen.daily_meal_count"].mean()
)
indicateurs["Nombre de repas moyens par jour pour les cantines centrales"] = int(
    cuisines_centrales["canteen.daily_meal_count"].mean()
)
indicateurs["Nombre de repas totaux pour l'année"] = int(td["canteen.yearly_meal_count"].sum())

indicateurs["Répartition du nombre de cantines en gestion directe"] = f"{100 * len(td[td['canteen.management_type'] == 'direct']) / len(td):.2f} %"
indicateurs[
    "Répartition du nombre de cantines en gestion concédée"
] = f"{100 * len(td[td['canteen.management_type'] == 'conceded']) / len(td):.2f} %"
indicateurs[
    "Répartition du nombre de cantines en gestion non renseignée"
] = f"{100 * len(td[~td['canteen.management_type'].isin(['direct', 'conceded'])]) / len(td):.2f} %"
```


Pour les montants, nous nous rebasons sur les données de TD.

```{python Montants d'achat alimentaires déclarés}
indicateurs["Montants d'achat alimentaires déclarés"] = f"{int(td['teledeclaration.value_total_ht'].sum())} €"

indicateurs[
    "Taux global des achats en bio"
] = f"{100 * td['teledeclaration.value_bio_ht'].sum() / td['teledeclaration.value_total_ht'].sum():.2f} %"

indicateurs[
    "Taux global des achats EGALIM (bio inclus)"
] = f"{100 * (td['teledeclaration.value_egalim_others_ht'].sum() + td['teledeclaration.value_externality_performance_ht'].sum() + td['teledeclaration.value_bio_ht'].sum()  + td['teledeclaration.value_sustainable_ht'].sum()) / td['teledeclaration.value_total_ht'].sum():.2f} %"

indicateurs['Nombre de TD ayant déclaré 0€ d\'achats en Bio'] = len(td[td['teledeclaration.value_bio_ht'] == 0])

for i in indicateurs:
    print(i, indicateurs[i])
```


```{python Vérification de la non existence de TD tests}
import re

pattern = r"test|testing|sample|temp|debug|beta"
mask = td["name"].str.contains(pattern, flags=re.IGNORECASE, regex=True)
testing_elements = td[mask]
```

```{python Vérification du taux de présence de la donnée repas par an}
print(
    f"Le taux de présence de la donnée repas par an est de {100 * (1 - td['canteen.yearly_meal_count'].isna().sum() / len(td)):.2f} %"
)
```


# Traitement des champs manquants, stratégie 2022

## Stratégie 2022

Si les 4 champs sont vides => on ne force pas à 0 (108 cantines concernés)

* Pour le calcul du bio -> mettre les valeurs à 0
* Pour le calcul du EGAlim -> mettre les valeurs à 0

* Pour les TD complètes de la campagne , on ne retrouvait pas les bonnes valeurs : total bio et somme des achats bio
22 TD complètes. Le total des achats bio est rempli automatiquement. Le calcul ne correspondait pas à la somme de tous les produits bio. Corrigé ?


## Stratégie 2023

* Normalement, champ "je ne sais pas"
* Import par fichiers, il y a peut-être des champs vides, ou des valeurs à 0


# Changelog pour la campagne 2022

* Supprimer les cuisine centrales du calcul du nombre de site de restauration concerné
* Se rebaser sur les données cantine fournies dans la télédéclaration
* Nombre de repas moyen : on se rebase sur les données cantine fournies dans la télédéclaration (et non pas une approximation détaillée par secteur)
* (eventuellement) Changer la stratégie pour les champs vides

# Analyses à mener 

* Pertinence des garde fous (bloquant et non bloquant) (cf Matomo)
* Nombre de déclarants ont rempli des valeurs d'achat bio (O € compris)
* Même télédeclarant que l'année dernière ? est-ce que leur pourcentage de bio est cohérent avec l'année dernière ?
* Est-ce que les nouveaux télédeclarants ont un pourcentage de bio qui contribue à la baisse ou à la hausse du pourcentage de bio global ?
* Répartition individuelle des des répartition du bio . Moyenne du pourcentage
* Stats par familles d'achat
* Mesurer l'effort de TD entre 3 semaine avant la date limite et la date limite